###############
# DESCRIPTION #
###############

# Python code to analyze saved data files generated by meta-RL program.


##############
# PARAMETERS #
##############

#data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180914_000352'   # summary saved every 50 episodes
#data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180918_211807'
#data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180921_011111'
#data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180923_114142'
#data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180924_175630'
#data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180924_235841'
#data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180926_002716'
#data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180928_233909'
#data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180929_001701'
data_path = '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20181002_010133'

#data_path = 'C:/Users/atiro/Dropbox/Schizophrenia_Model/saved_data/20180928_233909'

# data path for activity analysis
#data_path = './saved_data/20180920_130605'

# data path for variables analysis
#data_path='/home/atiroms/Documents/GitHub/Schizophrenia_Model/Model_03/saved_data/20181002_004726'

data_paths=[
    '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180918_211807',
    '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180921_011111',
    '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180923_114142',
    '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180924_175630',
    '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180924_235841',
    '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180926_002716',
    '/home/atiroms/Documents/Dropbox/Schizophrenia_Model/saved_data/20180928_233909',
]


#############
# LIBRARIES #
#############

import numpy as np
import pandas as pd
import tensorflow as tf
#import matplotlib.pyplot as plt
import plotly as py
import cufflinks as cf
import glob
import os
import math


##############################
# DATA EXTRACTION AND SAVING #
##############################

class Extract_Checkpoint():
    def __init__(self,data_path=data_path):
        # Collect summary files
        self.data_path=data_path + '/summary'
        self.data_paths = glob.glob(os.path.join(self.data_path, '*', 'event*'))

        # Extract data from summary files
        print('Starting data extraction.')
        for p in self.data_paths:
            count=0
            for e in tf.train.summary_iterator(p):
                print('Extracting episode ' + str(int(e.step)), end='\r')
                if count==1:
                #if count==0:
                    colnames=['Simulation/Global Episode Count']+[v.tag for v in e.summary.value]
                    self.output=pd.DataFrame(columns=colnames)

                if count>0:
                #if count>-1:
                    data=[e.step]+[v.simple_value for v in e.summary.value]
                    self.output.loc[count]=data
                count+=1

        print('\n')
        print('Finished data extraction. ' + str(count) + ' timepoints.')
        print('Saving extracted data.')

        # Save summary files in hdf5 format
        # '/' cannot be used as column names when stored in hdf5, so column names are stored separately
        colnames=pd.Series(self.output.columns.values,index=('col'+str(i) for i in range(self.output.shape[1])))
        self.output.columns=list('col'+str(i) for i in range(self.output.shape[1]))
        hdf=pd.HDFStore(self.data_path+'/summary.h5')
        hdf.put('summary',self.output,format='table',append=False,data_columns=True)
        hdf.put('colnames',colnames)
        hdf.close()
        self.output.columns=colnames.tolist()
        print('Finished saving data.')


#####################
# HDF5 DATA LOADING #
#####################

class Load_Summary():
    def __init__(self,data_path=data_path):
        print('Starting hdf5 file loading.')
        self.data_path=data_path + '/summary'
        hdf = pd.HDFStore(self.data_path+'/summary.h5')
        self.output = pd.DataFrame(hdf['summary'])
        self.output.columns=hdf['colnames'].tolist()
        hdf.close()
        print('Finished hdf5 file loading.')


class Load_Activity():
    def __init__(self,data_path=data_path):
        print('Starting hdf5 file loading.')
        self.data_path=data_path + '/activity'
        hdf = pd.HDFStore(self.data_path+'/activity.h5')
        self.output = pd.DataFrame(hdf['activity'])
        hdf.close()
        print('Finished hdf5 file loading.')


class Load_Variable():
    def __init__(self,data_path=data_path):
        print('Starting hdf5 file loading.')
        self.data_path=data_path + '/model'
        hdf = pd.HDFStore(self.data_path+'/variable.h5')
        self.output = pd.DataFrame(hdf['variable'])
        hdf.close()
        print('Finished hdf5 file loading.')



#################
# VISUALIZATION #
#################

class Visualize():
    def __init__(self,dataframe,data_path=data_path,key='Performance/Reward'):
        self.df=dataframe
        self.data_path=data_path
        self.key=key
        #cf.set_config_file(offline=True, theme="white", offline_show_link=False)
        #cf.go_offline()
        #df.plot(x='Simulation/Global Episode Count', y='Performance/Reward')
        #plt.show()
        #df.iplot(kind="scatter", mode='markers', x='Simulation/Global Episode Count', y='Performance/Reward')

        fig = self.df.iplot(
            kind="scatter", asFigure=True,x='Simulation/Global Episode Count', y='Performance/Reward',
            title='Reward - Episode', xTitle='Episode', yTitle='Reward',
            colors=['blue'])
        #fig = df.iplot(kind="scatter",  asFigure=True,x='Simulation/Global Episode Count', y='Perf/Reward')
        py.offline.plot(fig, filename=self.data_path + '/Reward.html')
        print('Generated graph.')


#########################
# AVERAGE OVER EPISODES #
#########################

class AveEpisode():
    def __init__(self,dataframe,interval):
        self.input=dataframe
        self.interval=interval
        self.length=math.floor(len(self.input)/self.interval)
        self.calc_average()

    def calc_average(self):
        print('Starting calculation of averages.')
        print('Calculating averages over ' + str(self.interval) + ' episodes.')
        self.output=pd.DataFrame(columns=self.input.columns)
        for i in range(self.length):
            self.output=self.output.append(self.input.iloc[(self.interval*i):(self.interval*(i+1)),:].mean(),ignore_index=True)
        print('Finished calculating averages.')


##############################
# REWARD AVERAGE GRAPH BATCH #
##############################

class RewardAverageGraphBatch():
    def __init__(self,data_paths=data_paths):
        for p in data_paths:
            print('Calculating ' + p + '.')
            df=Load_Summary(data_path=p).output
            ave=AveEpisode(dataframe=df,interval=100).output
            vis=Visualize(dataframe=ave,data_path=p)
        print('Finished batch calculation.')


print('End of file.')