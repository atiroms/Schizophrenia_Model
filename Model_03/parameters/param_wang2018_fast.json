{
    "//":"Reinforcement learning agent type",
    "agent": "A2C",

    "//":"Number of agents that act in parallel",
    "n_agents" : 1,
    
    "//":"Number of cells in LSTM-RNN network",
    "n_cells_lstm" : 48,

    "bootstrap_value" : 0.0,

    "//":"Task environment: 'Two_Armed_Bandit', 'Dual_Assignment_with_Hold'",
    "environment" : "Two_Armed_Bandit",

    "//":"Task configuration, select 'independent' for independent bandit",
    "config_environment" : "uniform",
    
    "//":"Discount rate for advantage estimation and reward discounting, '0.9' in Wang Nat Neurosci 2018, '0.7' in awjuliani/meta-RL",
    "gamma" : 0.9,

    "//":"'RMSProp' in Wang 2018, 'Adam' in awjuliani/meta-RL",
    "optimizer" : "RMSProp",

    "//":"'0.0007' in Wang Nat Neurosci 2018, '1e-3' in awjuliani/meta-RL",
    "learning_rate" : 0.007,

    "//":"'0.05' in Wang 2018, '0.5' in awjuliani/meta-RL",
    "cost_statevalue_estimate" : 0.05,

    "//":"'0.05' in Wang 2018 and awjuliani/meta-RL",
    "cost_entropy" : 0.05,

    "//":"Dummy counter used for batch calculation",
    "dummy_counter" : 0
}