{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36664bittensorflowcondadaf6c54e63c544bb8ec877604aaecab0",
   "display_name": "Python 3.6.6 64-bit ('tensorflow': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "End of file.\n"
    }
   ],
   "source": [
    "######################################################################\n",
    "# Description ########################################################\n",
    "######################################################################\n",
    "'''\n",
    "Python code for meta reinforcement learning\n",
    "For a single simulation,\n",
    "  sim=Sim()\n",
    "  sim.run()\n",
    "For batch simulations,\n",
    "  batch=Batch()\n",
    "  batch.run()\n",
    "'''\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Parameters #########################################################\n",
    "######################################################################\n",
    "\n",
    "set_param_sim='param_sim.json'\n",
    "#set_param_sim='param_sim_long.json'\n",
    "#set_param_sim='param_test.json'\n",
    "#set_param_sim='param_test_load.json'\n",
    "\n",
    "set_param_mod='param_wang2018.json'\n",
    "#set_param_mod='param_wang2018_parallel.json'\n",
    "\n",
    "#dir_restart='20200219_223846'\n",
    "#dir_restart='20200221_234851'\n",
    "#dir_restart='20200222_002120'\n",
    "dir_restart=None\n",
    "\n",
    "dir_load='20200222_002120/20200222_122717'\n",
    "#dir_load=None\n",
    "\n",
    "param_batch=[\n",
    "    #{'name': 'learning_rate', 'n':11, 'type':'parametric','method':'grid','min':0.0002,'max':0.0052}\n",
    "    #{'name': 'learning_rate', 'n':10, 'type':'parametric','method':'grid','min':0.0057,'max':0.0102},\n",
    "    #{'name': 'learning_rate', 'n':100, 'type':'parametric','method':'grid','min':0.0001,'max':0.0100},\n",
    "    #{'name': 'learning_rate', 'n':2, 'type':'parametric','method':'grid','min':0.0001,'max':0.0100},\n",
    "    #{'name':'dummy_counter', 'n':3, 'type':'parametric', 'method':'grid', 'min':0,'max':2}\n",
    "    #{'name':'learning_rate', 'n':5, 'type':'parametric', 'method':'random', 'min':0.0001, 'max':0.001},\n",
    "    #{'name':'optimizer', 'n':2, 'type':'list','list':['RMSProp','Adam']}\n",
    "    #{'name':'gamma','n':3,'type':'parametric','method':'grid','min':0.7,'max':0.9}\n",
    "    #{'name': 'n_cells_lstm', 'n':20, 'type':'parametric','method':'grid','min':5,'max':100}\n",
    "    {'name': 'learning_rate', 'n':19, 'type':'parametric','method':'grid','min':0.0001,'max':0.0019},\n",
    "    #{'name': 'learning_rate', 'n':17, 'type':'parametric','method':'grid','min':0.002,'max':0.01}\n",
    "    #{'name': 'episode_stop', 'n':5, 'type':'parametric','method':'grid','min':50000,'max':0.01}\n",
    "]\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Libraries ##########################################################\n",
    "######################################################################\n",
    "\n",
    "import os\n",
    "list_path_code=[\n",
    "    'D:/atiroms/GitHub/Schizophrenia_Model/Model_03',\n",
    "    'C:/Users/atiro/GitHub/Schizophrenia_Model/Model_03',\n",
    "    '/home/atiroms/GitHub/Schizophrenia_Model/Model_03'\n",
    "]\n",
    "for i in range(len(list_path_code)):\n",
    "    if os.path.exists(list_path_code[i]):\n",
    "        path_code=list_path_code[i]\n",
    "        os.chdir(path_code)\n",
    "        break\n",
    "    elif i==len(list_path_code)-1:\n",
    "        raise ValueError('Code folder does not exist in the list.')\n",
    "list_path_save=[\n",
    "    \"/media/veracrypt1/Machine_Learning/Schizophrenia_Model/saved_data\",\n",
    "    \"/media/atiroms/MORITA_HDD3/Machine_Learning/Schizophrenia_Model/saved_data\",\n",
    "    \"C:/Users/atiro/Documents/Machine_Learning/Schizophrenia_Model/saved_data\",\n",
    "    \"D:/Machine_Learning/Schizophrenia_Model/saved_data\",\n",
    "    \"F:/Machine_Learning/Schizophrenia_Model/saved_data\"\n",
    "]\n",
    "for i in range(len(list_path_save)):\n",
    "    if os.path.exists(list_path_save[i]):\n",
    "        path_save=list_path_save[i]\n",
    "        break\n",
    "    elif i==len(list_path_save)-1:\n",
    "        raise ValueError('Save folder does not exist in the list.')\n",
    "\n",
    "import threading\n",
    "#import multiprocessing\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import Agent\n",
    "import Network\n",
    "import Environment\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Parameters class for parameter exchange between classes ############\n",
    "######################################################################\n",
    "\n",
    "class Parameters():\n",
    "    def __init__(self,set_param,path_code=path_code):\n",
    "        self.set=None\n",
    "        self.add_json(set_param,path_code)\n",
    "\n",
    "    def add_dict(self,dict_param):\n",
    "        for key,value in dict_param.items():\n",
    "            if key!=\"//\":\n",
    "                setattr(self,key,value)\n",
    "\n",
    "    def add_json(self,set_param,path_code=path_code):\n",
    "        with open(os.path.join(path_code,\"parameters\",set_param)) as f:\n",
    "            dict_param=json.load(f)\n",
    "            self.add_dict(dict_param)\n",
    "        if self.set is None:\n",
    "            self.set=list()\n",
    "        self.set.append(set_param)\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Single run of simulation ###########################################\n",
    "######################################################################\n",
    "\n",
    "class Sim():\n",
    "    #def __init__(self,param_basic=param_basic,param_change=None):\n",
    "    def __init__(self,set_param_sim=set_param_sim,set_param_mod=set_param_mod,\n",
    "                 set_param_overwrite=None,\n",
    "                 path_code=path_code,path_save=path_save,\n",
    "                 path_save_batch=None,\n",
    "                 dir_load=dir_load):\n",
    "\n",
    "        # Timestamping directory name\n",
    "        datetime_start=\"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "        if path_save_batch is not None:\n",
    "            path_save_run=os.path.join(path_save_batch,datetime_start)\n",
    "        else:\n",
    "            path_save_run=os.path.join(path_save,datetime_start)\n",
    "        self.path_save=path_save\n",
    "\n",
    "        # Setup parameters in Parmeters object\n",
    "        self.param=Parameters(set_param_sim,path_code)\n",
    "        self.param.add_json(set_param_mod,path_code)\n",
    "        self.param.add_dict({'datetime_start':datetime_start, 'path_save':path_save_run})\n",
    "        if set_param_overwrite is not None:\n",
    "            self.param.add_dict(set_param_overwrite)\n",
    "        if dir_load is not None:\n",
    "            with open(os.path.join(path_save,dir_load,\"parameters.json\")) as f:\n",
    "                dict_param=json.load(f)\n",
    "            episode_done=dict_param['episode_stop']\n",
    "            episode_stop=episode_done+self.param.episode_stop\n",
    "            print('episode_stop='+str(episode_done)+'+'+str(self.param.episode_stop))\n",
    "            self.param.add_dict({'load_model':1,'dir_load':dir_load,'episode_stop':episode_stop})\n",
    "        else:\n",
    "            self.param.add_dict({'load_model':0})\n",
    "\n",
    "\n",
    "        # Make directories for saving\n",
    "        if not os.path.exists(self.param.path_save):\n",
    "            os.makedirs(self.param.path_save)\n",
    "        for subdir in ['model','pic','summary','activity']:\n",
    "            if not os.path.exists(os.path.join(self.param.path_save,subdir)):\n",
    "                os.makedirs(os.path.join(self.param.path_save,subdir))\n",
    "        \n",
    "        # Save parameters\n",
    "        with open(os.path.join(self.param.path_save,'parameters.json'), 'w') as fp:\n",
    "            json.dump(self.param.__dict__, fp, indent=1)\n",
    "\n",
    "    def run(self):\n",
    "        print('Running: '+ self.param.datetime_start + '.')\n",
    "        tf.reset_default_graph()\n",
    "        # Setup agents for multiple threading\n",
    "        with tf.device(self.param.xpu):\n",
    "            # counter of total episodes defined outside A2C_Agent class\n",
    "            self.episode_global = tf.Variable(0,dtype=tf.int32,name='episode_global',trainable=False)\n",
    "            if self.param.optimizer == \"Adam\":\n",
    "                self.trainer = tf.train.AdamOptimizer(learning_rate=self.param.learning_rate)\n",
    "            elif self.param.optimizer == \"RMSProp\":\n",
    "                self.trainer = tf.train.RMSPropOptimizer(learning_rate=self.param.learning_rate)\n",
    "            if self.param.environment == 'Two_Armed_Bandit':\n",
    "                env_alias=Environment.Two_Armed_Bandit\n",
    "            elif self.param.environment == 'Dual_Assignment_with_Hold':\n",
    "                env_alias=Environment.Dual_Assignment_with_Hold\n",
    "            # Generate master network\n",
    "            self.master_network = Network.LSTM_RNN_Network(self.param,\n",
    "                                                           env_alias(self.param.config_environment).n_actions,\n",
    "                                                           'master',None) \n",
    "            #n_agents = multiprocessing.cpu_count() # Set agents to number of available CPU threads\n",
    "            self.saver = tf.train.Saver(max_to_keep=5)\n",
    "            self.agents = []\n",
    "            # Create A2C_Agent classes (local network is defined within agent definition)\n",
    "            for i in range(self.param.n_agents):\n",
    "                self.agents.append(Agent.A2C_Agent(i,self.param,env_alias(self.param.config_environment),\n",
    "                                                   self.trainer,self.saver,self.episode_global))\n",
    "\n",
    "        # Run agents\n",
    "        #config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)\n",
    "        config=tf.ConfigProto(allow_soft_placement=True)\n",
    "        with tf.Session(config=config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            if self.param.load_model == True:\n",
    "                #ckpt = tf.train.get_checkpoint_state(self.param.path_load+'/model')\n",
    "                path_load=os.path.join(self.path_save,self.param.dir_load)\n",
    "                ckpt = tf.train.get_checkpoint_state(os.path.join(path_load,'model'))\n",
    "                self.saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "                print('Loaded parameters: '+ self.param.dir_load + '.')\n",
    "            #else:\n",
    "                #sess.run(tf.global_variables_initializer())\n",
    "            coord = tf.train.Coordinator()\n",
    "            #if self.param.xpu=='/gpu:0' and self.param.n_agents==1:\n",
    "            if self.param.n_agents==1:\n",
    "                self.agents[0].work(sess,coord)\n",
    "            elif self.param.xpu=='/gpu:0' and self.param.n_agents>1:\n",
    "                raise ValueError('Multi-threading not allowed with GPU.')\n",
    "            else:\n",
    "                agent_threads = []\n",
    "                for agent in self.agents:\n",
    "                    agent_work = lambda: agent.work(sess,coord)\n",
    "                    thread = threading.Thread(target=(agent_work))\n",
    "                    thread.start()\n",
    "                    agent_threads.append(thread)\n",
    "                coord.join(agent_threads)\n",
    "        print('Done single run: '+ self.param.datetime_start + '.')\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Batch run of simulations ###########################################\n",
    "######################################################################\n",
    "\n",
    "class Batch():\n",
    "    def __init__(self,param_batch=param_batch,path_save=path_save,\n",
    "                 dir_restart=dir_restart):\n",
    "        if dir_restart is None:\n",
    "            self.prep(param_batch=param_batch,path_save=path_save)\n",
    "        else:\n",
    "            self.prep_restart(dir_restart=dir_restart,path_save=path_save)\n",
    "\n",
    "    def prep_restart(self,dir_restart,path_save):\n",
    "        self.path_save_batch=os.path.join(path_save,dir_restart)\n",
    "        if os.path.exists(os.path.join(self.path_save_batch,\"batch_table.h5\")):\n",
    "            with pd.HDFStore(os.path.join(self.path_save_batch,\"batch_table.h5\")) as hdf:\n",
    "                self.batch_table = pd.DataFrame(hdf['batch_table'])\n",
    "            self.batch_table.loc[:,'run']=False\n",
    "            list_idx_rerun=self.batch_table.loc[self.batch_table['done']==False,:].index.values.tolist()\n",
    "            print('Unfinished runs: '+str(len(list_idx_rerun))+'.')\n",
    "            for i in list_idx_rerun:\n",
    "                sr_append=self.batch_table.loc[i,:]\n",
    "                sr_append['datetime_start']=np.NaN\n",
    "                sr_append['run']=True\n",
    "                sr_append['done']=False\n",
    "                self.batch_table=self.batch_table.append(sr_append)\n",
    "            self.batch_table=self.batch_table.reset_index(drop=True)\n",
    "            self.save_batch_table()\n",
    "            print('Done batch setup for restart.')\n",
    "        else:\n",
    "            print('dir_restart not found: '+dir_restart)\n",
    "\n",
    "    def prep(self,param_batch=param_batch,path_save=path_save):\n",
    "        self.n_param=len(param_batch)\n",
    "        # Timestamping directory name\n",
    "        datetime_start=\"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "        self.path_save_batch=os.path.join(path_save,datetime_start)\n",
    "        if not os.path.exists(self.path_save_batch):\n",
    "            os.makedirs(self.path_save_batch)\n",
    "\n",
    "        # Batch table preparation\n",
    "        batch_current_id=np.zeros((self.n_param,),dtype=np.int16) # table of ids of iteration for each parameter\n",
    "        self.batch_table=pd.DataFrame()\n",
    "        batch_count=0\n",
    "        flag_break=0        # 1: batch current id update successfull, 2: end of recursion\n",
    "        while flag_break < 2:\n",
    "            for i in range(self.n_param):\n",
    "                param=param_batch[i]\n",
    "                if param['type']=='list':\n",
    "                    self.batch_table.loc[batch_count,param['name']] = param['list'][batch_current_id[i]]\n",
    "                elif param['type']=='parametric':\n",
    "                    if param['method']=='grid':\n",
    "                        self.batch_table.loc[batch_count,param['name']] = param['min']+(param['max']-param['min'])*batch_current_id[i]/(param['n']-1)\n",
    "                    elif param['method']=='random':\n",
    "                        self.batch_table.loc[batch_count,param['name']] = np.random.uniform(low=param['min'],high=param['max'])\n",
    "                else:\n",
    "                    raise ValueError('Incorrect batch parameter type.')\n",
    "\n",
    "            param_id_level=self.n_param-1\n",
    "            flag_break=0\n",
    "            while flag_break < 1:\n",
    "                batch_current_id[param_id_level] += 1\n",
    "                if batch_current_id[param_id_level] < param_batch[param_id_level]['n']:\n",
    "                    # break updating id when within limit\n",
    "                    flag_break = 1\n",
    "                else:\n",
    "                    # reset current level to 0\n",
    "                    batch_current_id[param_id_level] = 0\n",
    "                    # move to the upper level\n",
    "                    param_id_level -= 1\n",
    "                    if param_id_level < 0:\n",
    "                        # break creating list when reached end\n",
    "                        flag_break = 2\n",
    "\n",
    "            batch_count += 1\n",
    "\n",
    "        self.batch_table.loc[:,'datetime_start']=np.NaN\n",
    "        self.batch_table.loc[:,'run']=True\n",
    "        self.batch_table.loc[:,'done']=False\n",
    "        self.save_batch_table()\n",
    "\n",
    "        with open(self.path_save_batch+'/parameters_batch.json', 'w') as fp:\n",
    "            json.dump(param_batch, fp, indent=1)\n",
    "\n",
    "        print('Done batch setup.')\n",
    "\n",
    "    def run(self):\n",
    "        batch_table_run=self.batch_table.loc[self.batch_table['run']==True,:]\n",
    "        #for i in range(len(self.batch_table)):\n",
    "        list_idx_run=batch_table_run.index.values.tolist()\n",
    "        for i in range(len(list_idx_run)):\n",
    "            idx=list_idx_run[i]\n",
    "            print('Batch simulation: ' + str(i + 1) + '/' + str(len(list_idx_run)),'.')\n",
    "            param_overwrite=self.batch_table.loc[idx,self.batch_table.columns.difference(['datetime_start','run','done'])].to_dict()\n",
    "            param_overwrite['path_save_batch']=self.path_save_batch\n",
    "            sim=Sim(path_save_batch=self.path_save_batch,set_param_overwrite=param_overwrite)\n",
    "            self.batch_table.loc[idx,'datetime_start']=sim.param.datetime_start\n",
    "            self.save_batch_table()\n",
    "            sim.run()\n",
    "            self.batch_table.loc[idx,'done']=True\n",
    "            self.save_batch_table()\n",
    "        print('Done batch simulation.')\n",
    "\n",
    "    def save_batch_table(self):\n",
    "        hdf=pd.HDFStore(self.path_save_batch+'/batch_table.h5')\n",
    "        hdf.put('batch_table',self.batch_table,format='table',append=False,data_columns=True)\n",
    "        hdf.close()\n",
    "\n",
    "print('End of file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "episode_stop=200000+50000\n"
    }
   ],
   "source": [
    "sim=Sim()\n",
    "\n",
    "#sim.param.n_cells_lstm=5\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.device(sim.param.xpu):\n",
    "    \n",
    "    env_alias=Environment.Two_Armed_Bandit\n",
    "\n",
    "    sim.episode_global = tf.Variable(0,dtype=tf.int32,name='episode_global',trainable=False)\n",
    "\n",
    "    sim.master_network = Network.LSTM_RNN_Network(sim.param,\n",
    "                                                  env_alias(sim.param.config_environment).n_actions,\n",
    "                                                  'master',None) \n",
    "            \n",
    "    sim.saver = tf.train.Saver(max_to_keep=5)\n",
    "    sim.trainer = tf.train.RMSPropOptimizer(learning_rate=sim.param.learning_rate)\n",
    "\n",
    "    sim.agents = []\n",
    "    sim.agents.append(Agent.A2C_Agent(0,sim.param,env_alias(sim.param.config_environment),sim.trainer,sim.saver,sim.episode_global))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "flag1\nflag2\nflag3\n"
    }
   ],
   "source": [
    "config=tf.ConfigProto(allow_soft_placement=True)\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if sim.param.load_model == True:\n",
    "        print('flag1')\n",
    "        path_load=os.path.join(sim.path_save,sim.param.dir_load)\n",
    "        print('flag2')\n",
    "        ckpt = tf.train.get_checkpoint_state(os.path.join(path_load,'model'))\n",
    "        print('flag3')\n",
    "        sim.saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        print('flag4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "vars_master = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,'master')\n",
    "vars_agent0 = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,'agent_0')\n",
    "val_initialized = sess.run(vars_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[-0.02231593, -0.11901327,  0.00786129, ..., -0.00623253,\n          0.02882232, -0.11126006],\n        [-0.0038497 , -0.13963783, -0.1122891 , ..., -0.08820447,\n          0.07871552, -0.05982043],\n        [ 0.12976271, -0.07109986, -0.0805642 , ...,  0.15223715,\n          0.13204968,  0.13279292],\n        ...,\n        [ 0.01041928, -0.12611176, -0.09581986, ..., -0.12980406,\n         -0.01876847,  0.0453749 ],\n        [-0.05050568,  0.15561897,  0.09143354, ...,  0.07984376,\n          0.13569516,  0.0854059 ],\n        [ 0.15186548,  0.01911968,  0.0140678 , ..., -0.0792825 ,\n          0.14054695, -0.07097077]], dtype=float32),\n array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0.], dtype=float32),\n array([[-2.4283149e-03,  1.7482596e-03],\n        [ 1.3669724e-04,  3.9055053e-04],\n        [-8.0339884e-04, -1.4437574e-03],\n        [-7.9740927e-04, -1.1295745e-03],\n        [ 1.2389994e-03, -1.0789268e-03],\n        [ 9.3527976e-04,  9.7913714e-04],\n        [-5.3486432e-04,  2.4190065e-03],\n        [ 6.4735528e-04,  2.6914366e-03],\n        [-2.3277584e-03, -2.3394006e-03],\n        [-5.1154307e-04, -8.1009284e-04],\n        [-1.0812692e-03, -7.9867756e-04],\n        [ 6.3962588e-04, -3.5679140e-03],\n        [-1.0969357e-03,  3.0124149e-05],\n        [-1.1383637e-03, -7.6237353e-05],\n        [-4.0779926e-04,  2.0505815e-04],\n        [-1.1865830e-03,  1.6757991e-03],\n        [ 5.5309437e-04,  1.3535200e-03],\n        [-2.5945143e-03, -3.3083095e-04],\n        [ 2.1987204e-03, -7.0012815e-04],\n        [ 1.2896649e-03, -2.5372349e-03],\n        [-7.2752795e-05, -8.2773517e-04],\n        [ 3.3461911e-05,  2.0755844e-03],\n        [-4.3970707e-04, -1.5579722e-03],\n        [-2.2361425e-03, -1.1769267e-04],\n        [-1.8963012e-03, -5.3947244e-04],\n        [-9.8963303e-04,  8.0977927e-04],\n        [-5.0321429e-05, -1.3278964e-03],\n        [-1.5529157e-03,  1.2702913e-03],\n        [-1.5399259e-03,  8.7073189e-04],\n        [-4.1047581e-03,  7.5762818e-04],\n        [-3.6062908e-04,  8.6555682e-04],\n        [-1.3174156e-03, -9.6343516e-05],\n        [ 7.9899793e-04,  5.3859239e-05],\n        [-1.5598700e-03, -7.0273137e-04],\n        [-1.5545919e-03,  1.2030962e-03],\n        [ 1.9997801e-03, -1.5010299e-03],\n        [-1.1578548e-03,  1.6770998e-03],\n        [ 1.8458979e-04, -1.4657186e-03],\n        [-7.4800698e-04, -1.5137900e-03],\n        [ 6.5031834e-04, -2.2245613e-03],\n        [-3.4027387e-04, -1.9210769e-04],\n        [-2.2182849e-04,  1.6832107e-03],\n        [ 5.9751817e-04, -1.1438063e-03],\n        [-1.2561465e-03, -1.6066330e-03],\n        [ 6.0303509e-04,  1.3449248e-03],\n        [-5.8467867e-04,  2.0803851e-03],\n        [-2.1531524e-03,  3.5647652e-05],\n        [-3.5013980e-03,  1.9606864e-03]], dtype=float32),\n array([[ 0.07428812],\n        [-0.08982274],\n        [ 0.03737263],\n        [ 0.2153653 ],\n        [-0.05506658],\n        [-0.12033956],\n        [-0.11171892],\n        [ 0.03245084],\n        [ 0.12605849],\n        [ 0.2666733 ],\n        [ 0.10916691],\n        [ 0.07177   ],\n        [-0.01840802],\n        [ 0.02368827],\n        [-0.04625737],\n        [ 0.17882441],\n        [ 0.03228425],\n        [ 0.10404941],\n        [ 0.07655716],\n        [-0.20175764],\n        [-0.2033106 ],\n        [-0.30704996],\n        [ 0.10513985],\n        [ 0.07159171],\n        [-0.06936695],\n        [-0.0169542 ],\n        [-0.16604   ],\n        [-0.2292138 ],\n        [ 0.15731457],\n        [-0.11495597],\n        [-0.3984317 ],\n        [-0.10903673],\n        [-0.13445775],\n        [-0.02971136],\n        [-0.13738059],\n        [ 0.00462483],\n        [ 0.3340089 ],\n        [ 0.06844562],\n        [-0.16745006],\n        [-0.03244835],\n        [-0.13247152],\n        [-0.07529983],\n        [ 0.08755326],\n        [-0.1326627 ],\n        [-0.09203845],\n        [ 0.12523422],\n        [ 0.09170154],\n        [-0.01462583]], dtype=float32)]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[<tf.Variable 'master/rnn/LSTM_Cells/kernel:0' shape=(52, 192) dtype=float32_ref>,\n <tf.Variable 'master/rnn/LSTM_Cells/bias:0' shape=(192,) dtype=float32_ref>,\n <tf.Variable 'master/fully_connected/weights:0' shape=(48, 2) dtype=float32_ref>,\n <tf.Variable 'master/fully_connected_1/weights:0' shape=(48, 1) dtype=float32_ref>]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(tf.global_variables_initializer())\n",
    "path_load=os.path.join(sim.path_save,sim.param.dir_load)\n",
    "ckpt = tf.train.get_checkpoint_state(os.path.join(path_load,'model'))\n",
    "sim.saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "sess.run(vars_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}