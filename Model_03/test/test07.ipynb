{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36664bittensorflowcondadaf6c54e63c544bb8ec877604aaecab0",
   "display_name": "Python 3.6.6 64-bit ('tensorflow': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "End of file.\n"
    }
   ],
   "source": [
    "######################################################################\n",
    "# Description ########################################################\n",
    "######################################################################\n",
    "'''\n",
    "Python code to analyze saved data files generated by meta-RL program.\n",
    "\n",
    "Data to be extracted:\n",
    "activity/activity.h5\n",
    "    for each timestep within an episode at intervals specified in interval_activity,\n",
    "    actions, rewards, values, etc...\n",
    "model/checkpoint\n",
    "    for each episode at intervals specified in interval_ckpt,\n",
    "    model parameters in tensorflow default format\n",
    "model/variable.h5\n",
    "    for each episode at intervals specified in interval_var,\n",
    "    all the trainable variables of network\n",
    "pic/\n",
    "    for each episode at intervals specified in interval_pic,\n",
    "    gif images (movie) of all task actions within episode\n",
    "summary/summary.h5:\n",
    "    for each episode at intervals specified in interval_summary,\n",
    "    total reward, task arm probabilities, learning losses, etc...\n",
    "'''\n",
    "\n",
    "######################################################################\n",
    "# Parameters #########################################################\n",
    "######################################################################\n",
    "import os\n",
    "list_path_data=[\n",
    "    \"/media/veracrypt1/Machine_Learning/Schizophrenia_Model/saved_data\",\n",
    "    \"/media/atiroms/MORITA_HDD3/Machine_Learning/Schizophrenia_Model/saved_data\",\n",
    "    \"C:/Users/atiro/Documents/Machine_Learning/Schizophrenia_Model/saved_data\",\n",
    "    \"D:/Machine_Learning/Schizophrenia_Model/saved_data\",\n",
    "    \"F:/Machine_Learning/Schizophrenia_Model/saved_data\"\n",
    "]\n",
    "for i in range(len(list_path_data)):\n",
    "    if os.path.exists(list_path_data[i]):\n",
    "        path_data=list_path_data[i]\n",
    "        break\n",
    "    elif i==len(list_path_data)-1:\n",
    "        raise ValueError('Data folder does not exist in the list.')\n",
    "\n",
    "#dir_data='20200216_191229'\n",
    "#dir_data='20200216_204436'\n",
    "dir_data='20200216_233234' # n_cells_lstm 4, 15, ... 48\n",
    "#dir_data='20200217_103834'\n",
    "#dir_data='20200218_212228' # n_cells_lstm 5, 10, ... 100\n",
    "#dir_data='20200219_223846' # learning_rate 0.0001, 0.0002, ... 0.0019\n",
    "#dir_data='20200220_230830' # learning_rate 0.0020, 0.0025, ... 0.0100\n",
    "#dir_data='20200222_002120' # three long runs (200000)\n",
    "#dir_data='20200223_153711' # combined '20200219_223846' and '20200220_230830'\n",
    "#dir_data='20200222_233321' # learning_rate 0.0001, 0.0002, ... 0.0019 after loading '20200222_002120/20200222_122717'\n",
    "#dir_data='20200223_235457' # learning_rate 0.0020, 0.0025, ... 0.0100 after loading '20200222_002120/20200222_122717'\n",
    "#dir_data='20200224_220741' # combined '20200222_233321' and '20200223_235457'\n",
    "#dir_data='20200224_234232' # learning_rate 0.0150, 0.0200, ... 0.1000 after loading '20200222_002120/20200222_122717'\n",
    "#dir_data='20200226_153138' # n_cells_lstm 36,48,60 after loading '20200222_002120/20200222_122717'\n",
    "#dir_data='20200226_200910' # n_cells_lstm 12,16,...60 after loading '20200222_002120/20200222_122717'\n",
    "#dir_data='20200227_123416' # n_cells_lstm 4,8 after loading '20200222_002120/20200222_122717'\n",
    "#dir_data='20200227_151151' # combined '20200222_233321', '20200223_235457' and '20200224_234232' (learning_rate 0.0001-0.1000)\n",
    "#dir_data='20200227_150929' # combined '20200227_123416' and '20200226_200910' (n_cells_lstm 4-60)\n",
    "#dir_data='20200227_160031' # n_cells_lstm 1,2,..11 after loading '20200222_002120/20200222_122717'\n",
    "#dir_data='20200228_123122' # combined '20200227_160031' and '20200226_200910' (n_cells_lstm 1-60)\n",
    "#dir_data='20200228_130159' # n_cells_lstm 13,14,..36 after loading '20200222_002120/20200222_122717'\n",
    "#dir_data='20200229_210037' # combined '20200227_160031' and '20200228_130159' n_cells_lstm 1,2,..36 after loading '20200222_002120/20200222_122717'\n",
    "\n",
    "#dir_data='20200229_003524' # single run\n",
    "\n",
    "#list_dir_data=['20200219_223846','20200220_230830']\n",
    "#list_dir_data=['20200222_233321','20200223_235457','20200224_234232']\n",
    "#list_dir_data=['20200227_123416','20200226_200910']\n",
    "#list_dir_data=['20200227_160031','20200226_200910']\n",
    "list_dir_data=['20200227_160031','20200228_130159']\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Libraries ##########################################################\n",
    "######################################################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "import datetime\n",
    "import scipy.stats as stats\n",
    "#import tensorflow as tf\n",
    "#import plotly as py\n",
    "#import cufflinks as cf\n",
    "#import glob\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Combine multiple batches ###########################################\n",
    "######################################################################\n",
    "class BatchCombine():\n",
    "    def __init__(self, path_data=path_data,list_dir_data=list_dir_data):\n",
    "        self.path_data=path_data\n",
    "        self.df_batch=pd.DataFrame()\n",
    "        for dir_data in list_dir_data:\n",
    "            path_load_batch=os.path.join(path_data,dir_data)\n",
    "            if os.path.exists(path_load_batch):\n",
    "                # Read batch_table\n",
    "                with pd.HDFStore(os.path.join(path_load_batch,'batch_table.h5')) as hdf:\n",
    "                    df_batch_append = pd.DataFrame(hdf['batch_table'])\n",
    "                #df_batch_append=df_batch_append.loc[df_batch['done']==True,:]\n",
    "                self.df_batch=self.df_batch.append(df_batch_append)\n",
    "            else:\n",
    "                print(\"Batch dir does not exist: \"+dir_data+\".\")\n",
    "        \n",
    "        self.df_batch=self.df_batch.reset_index(drop=True)\n",
    "        print('Detected '+str(len(self.df_batch))+' runs.')\n",
    "\n",
    "    def combine(self):\n",
    "        # Timestamping directory name\n",
    "        datetime_start=\"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
    "        self.path_save_batch=os.path.join(self.path_data,datetime_start)\n",
    "        if not os.path.exists(self.path_save_batch):\n",
    "            os.makedirs(self.path_save_batch)\n",
    "\n",
    "        hdf=pd.HDFStore(self.path_save_batch+'/batch_table.h5')\n",
    "        hdf.put('batch_table',self.df_batch,format='table',append=False,data_columns=True)\n",
    "        hdf.close()\n",
    "        print('Saved new batch table.')\n",
    "        print('Please copy subdirectories manually.')\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Batch data analysis ################################################\n",
    "######################################################################\n",
    "\n",
    "class BatchAnalysis():\n",
    "    def __init__(self, path_data=path_data,dir_data=dir_data,subset={}):\n",
    "        self.path_load_batch=os.path.join(path_data,dir_data)\n",
    "        self.path_save_analysis=os.path.join(self.path_load_batch,\"analysis\")\n",
    "        if not os.path.exists(self.path_save_analysis):\n",
    "            os.makedirs(self.path_save_analysis)\n",
    "        self.subset=subset\n",
    "\n",
    "    def single_plot(self,key='reward',window=1000,padding=10):\n",
    "        with pd.HDFStore(self.path_load_batch+'/summary/summary.h5') as hdf:\n",
    "            summary = pd.DataFrame(hdf['summary'])\n",
    "        df_reward=summary[['episode',key]]\n",
    "\n",
    "        df_reward=self.ave_reward(df_reward,window=window,padding=padding)\n",
    "\n",
    "        print('Preparing line plot.')\n",
    "        #self.path=os.path.join(path_data,dir_data)\n",
    "        #self.df_ave=df_ave\n",
    "        fig=plt.figure(figsize=(5,2),dpi=100)\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        ax.plot(df_reward['episode'],df_reward[key])\n",
    "        ax.set_title(\"Average reward, window: \"+str(window)+\", padding: \"+str(padding))\n",
    "        ax.set_xlabel(\"Task episode\")\n",
    "        ax.set_ylabel(\"Reward\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.path_save_analysis,\n",
    "                                 \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())+'_reward.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def batch_load(self,key='reward'):\n",
    "        # Read batch_table\n",
    "        with pd.HDFStore(os.path.join(self.path_load_batch,'batch_table.h5')) as hdf:\n",
    "            df_batch = pd.DataFrame(hdf['batch_table'])\n",
    "        #df_batch = df_batch.iloc[0:10,:]\n",
    "        df_batch=df_batch.loc[df_batch['done']==True,:]\n",
    "        self.df_batch=df_batch\n",
    "\n",
    "        # Subset batch table by keys and values specified in 'subset'\n",
    "        if len(self.subset)>0:\n",
    "            for key in list(self.subset.keys()):\n",
    "                df_batch_subset=df_batch.loc[df_batch[key]==self.subset[key]]\n",
    "        else:\n",
    "            df_batch_subset=df_batch\n",
    "        column_batchlabel=df_batch_subset.columns.tolist()\n",
    "        for column in ['datetime_start','run','done']:\n",
    "            if column in column_batchlabel:\n",
    "                column_batchlabel.remove(column)\n",
    "\n",
    "        self.n_batch=len(df_batch_subset)\n",
    "        label_batch=None\n",
    "        for column in column_batchlabel:\n",
    "            if max(df_batch_subset[column].tolist())>1:\n",
    "                regex='{0:.0f}'\n",
    "            else:\n",
    "                regex='{:.4f}'\n",
    "            if label_batch is None:\n",
    "                label_batch=[regex.format(b) for b in df_batch_subset[column].tolist()]\n",
    "                title_batch=column\n",
    "            else:\n",
    "                label_batch=[a+'_'+regex.format(b) for a,b in zip(label_batch,df_batch_subset[column].tolist())]\n",
    "                title_batch=title_batch+'_'+column\n",
    "        self.label_batch=label_batch\n",
    "        self.title_batch=title_batch\n",
    "\n",
    "        # Read subdirectory using subset of batch table\n",
    "        print('Loading data.')\n",
    "        sleep(1)\n",
    "        for i in tqdm(range(self.n_batch)):\n",
    "            #print('\\rLoading ' + str(i+1) + '/' + str(self.n_batch) + '                 ',end='')\n",
    "            subdir=df_batch_subset['datetime_start'].iloc[i]\n",
    "            path=self.path_load_batch + '/' + subdir\n",
    "            with pd.HDFStore(path+'/summary/summary.h5') as hdf:\n",
    "                summary = pd.DataFrame(hdf['summary'])\n",
    "            \n",
    "            summary=summary[['episode',key]].rename(columns={key:str(i)})\n",
    "            if i == 0:\n",
    "                output=summary\n",
    "            else:\n",
    "                output=pd.merge(output,summary,how='outer', on='episode')\n",
    "        output['episode']=output['episode']-output.loc[0,'episode']\n",
    "        print('Finished loading data.')\n",
    "        #self.df_ave=MovAveEpisode(dataframe=self.summaries).output\n",
    "        return(output)\n",
    "\n",
    "    def ave_reward(self,df_reward,window=100,padding=10):\n",
    "        self.win_ave=window\n",
    "        self.pad_ave=padding\n",
    "        # len = win + (n-1) * pad    >>     n = (len - win)/pad + 1\n",
    "        len_out=int((len(df_reward)-window)/padding+1)\n",
    "        print('Averaging reward, window: '+str(window)+', padding: '+str(padding)+', output: '+str(len_out)+'.')\n",
    "        sleep(1)\n",
    "        output=pd.DataFrame(columns=['episode_start','episode_stop']+df_reward.columns.tolist())\n",
    "        for i in tqdm(range(len_out)):\n",
    "            output=output.append(pd.concat([pd.Series([i*padding,i*padding+window-1],index=['episode_start','episode_stop']),\n",
    "                                            df_reward.iloc[i*padding:(i*padding+window),:].mean()]),ignore_index=True)\n",
    "            #self.output=self.output.append(self.input.iloc[(self.interval*i):(self.interval*(i+1)),:].mean(),ignore_index=True)\n",
    "        print('Finished averaging reward.')\n",
    "        return(output)\n",
    "\n",
    "    def state_reward(self,df_reward,learned=False,threshold=[65,67.5]):\n",
    "        self.thresh_reward=threshold\n",
    "        print('Calculating disease states.')\n",
    "        sleep(1)\n",
    "        col_batch=df_reward.drop(['episode','episode_start','episode_stop'],axis=1).columns.tolist()\n",
    "        if learned:\n",
    "            state_init=[1,0,0]\n",
    "        else:\n",
    "            state_init=[0,-1,0]\n",
    "        # State at each episode, 0: unlearned, 1: learned 2: psychotic 3: remitted\n",
    "        df_state=pd.DataFrame(state_init[0],columns=col_batch,index=df_reward.index).astype(int)\n",
    "        # State history, -1: never learned, 0: has learned, N>0: N psychotic episodes\n",
    "        df_count=pd.DataFrame(state_init[1],columns=col_batch,index=df_reward.index).astype(int)\n",
    "        # Cumulative psychosis\n",
    "        df_cumul=pd.DataFrame(state_init[2],columns=col_batch,index=df_reward.index)\n",
    "        #sr_state=pd.Series(-1,index=col_batch).astype(int)\n",
    "        for i in tqdm(range(1,len(df_reward))):\n",
    "            for col in col_batch:\n",
    "                df_cumul.loc[i,col]=df_cumul.loc[i-1,col]\n",
    "                if df_reward.loc[i,col]<threshold[0]:                           # Currently below threshold\n",
    "                    if df_state.loc[i-1,col]==0 or df_state.loc[i-1,col]==2:    # Stayed below threshold\n",
    "                        df_state.loc[i,col]=df_state.loc[i-1,col]                  # No change\n",
    "                        df_count.loc[i,col]=df_count.loc[i-1,col]\n",
    "                    else:                                                       # Fell below threshold\n",
    "                        df_state.loc[i,col]=2                                      # Fall psychotic                   \n",
    "                        df_count.loc[i,col]=df_count.loc[i-1,col]+1                # Count up psychosis\n",
    "                    if df_state.loc[i,col]==2:                                   # Currently psychotic\n",
    "                        df_cumul.loc[i,col]=df_cumul.loc[i-1,col]+(threshold[0]-df_reward.loc[i,col])*self.pad_ave\n",
    "                elif df_reward.loc[i,col]>=threshold[1]:                        # Currently above threshold\n",
    "                    if df_state.loc[i-1,col]==0 or df_state.loc[i-1,col]==2:    # Climbed above threshold\n",
    "                        if df_count.loc[i-1,col]==-1:                                   # Learned for the first time\n",
    "                            df_state.loc[i,col]=1\n",
    "                            df_count.loc[i,col]=0\n",
    "                        else:                                                   # Remitted\n",
    "                            df_state.loc[i,col]=3\n",
    "                            df_count.loc[i,col]=df_count.loc[i-1,col]\n",
    "                    else:                                                       # Stayed above threshold\n",
    "                        df_state.loc[i,col]=df_state.loc[i-1,col]                  # No change\n",
    "                        df_count.loc[i,col]=df_count.loc[i-1,col]\n",
    "                else:                                                           # Currently gray zone\n",
    "                    df_state.loc[i,col]=df_state.loc[i-1,col]                      # No change\n",
    "                    df_count.loc[i,col]=df_count.loc[i-1,col]\n",
    "        df_state=pd.concat([df_reward[['episode_start','episode_stop','episode']],df_state],axis=1)\n",
    "        df_count=pd.concat([df_reward[['episode_start','episode_stop','episode']],df_count],axis=1)\n",
    "        df_cumul=pd.concat([df_reward[['episode_start','episode_stop','episode']],df_cumul],axis=1)\n",
    "        print('Finished calculating disease states')\n",
    "        return([df_state,df_count,df_cumul])\n",
    "\n",
    "    def heatmap_reward(self,df_reward):\n",
    "        print('Preparing heatmap plot.')\n",
    "        df_plot=df_reward.drop(['episode','episode_start','episode_stop'],axis=1).T\n",
    "        df_plot.columns=df_reward['episode_start'].tolist()\n",
    "        df_plot.index=self.label_batch\n",
    "        self.df_plot=df_plot\n",
    "        fig=plt.figure(figsize=(6,0.75+0.13*len(df_plot)),dpi=100)\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        #heatmap=ax.pcolor(df_reward['episode_start'].tolist(),np.arange(self.n_batch+1),df_plot,cmap=cm.rainbow)\n",
    "        heatmap=ax.pcolor(df_reward['episode'].tolist(),np.arange(self.n_batch+1),df_plot,cmap=cm.rainbow_r)\n",
    "        #ax.set_xticks(np.arange(df_plot.shape[1]), minor=False)\n",
    "        ax.set_yticks(np.arange(df_plot.shape[0]) + 0.5, minor=False)\n",
    "        ax.invert_yaxis()\n",
    "        #ax.set_xticklabels([str(int(i)) for i in df_reward['episode_start'].tolist()], minor=False)\n",
    "        ax.set_yticklabels(self.label_batch, minor=False)\n",
    "        ax.set_title(\"Average reward, window: \"+str(self.win_ave)+\", padding: \"+str(self.pad_ave))\n",
    "        ax.set_xlabel(\"Task episode\")\n",
    "        ax.set_ylabel(self.title_batch)\n",
    "        cbar=fig.colorbar(heatmap,ax=ax)\n",
    "        cbar.set_label('Average reward')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.path_save_analysis,\n",
    "                                 \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())+'_heatmap.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_reward(self,df_reward):\n",
    "        print('Preparing line plot.')\n",
    "        #self.path=os.path.join(path_data,dir_data)\n",
    "        #self.df_ave=df_ave\n",
    "        fig=plt.figure(figsize=(6,5),dpi=100)\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        for i in range(self.n_batch):\n",
    "            ax.plot(df_reward['episode'],df_reward.drop(['episode_start','episode_stop','episode'],axis=1).iloc[:,i],\n",
    "                    color=cm.rainbow(i/self.n_batch))\n",
    "        ax.set_title(\"Average reward, window: \"+str(self.win_ave)+\", padding: \"+str(self.pad_ave))\n",
    "        ax.set_xlabel(\"Task episode\")\n",
    "        ax.set_ylabel(\"Reward\")\n",
    "        ax.legend(title=self.title_batch,labels=self.label_batch,\n",
    "                  bbox_to_anchor=(1.05,1),loc='upper left')\n",
    "        #ax.plot(np.arange(0,x_test.shape[0],1),y_test)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.path_save_analysis,\n",
    "                                 \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())+'_reward.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_state(self,df_state):\n",
    "        fig=plt.figure(figsize=(6,5),dpi=100)\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        for i in range(self.n_batch):\n",
    "            ax.plot(df_state['episode'],df_state.drop(['episode_start','episode_stop','episode'],axis=1).iloc[:,i],\n",
    "                    color=cm.rainbow(i/self.n_batch))\n",
    "        ax.set_yticks([0,1,2,3], minor=False)\n",
    "        ax.set_yticklabels(['unlearned','learned','psychotic','remitted'], minor=False)\n",
    "        ax.set_title(\"Disease state transision\")\n",
    "        ax.set_xlabel(\"Task episode\")\n",
    "        ax.set_ylabel(\"State\")\n",
    "        ax.legend(title=self.title_batch,labels=self.label_batch,\n",
    "                  bbox_to_anchor=(1.05,1),loc='upper left',fontsize=4)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.path_save_analysis,\n",
    "                                 \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())+'_state.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_count(self,df_count):\n",
    "        fig=plt.figure(figsize=(6,5),dpi=100)\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        for i in range(self.n_batch):\n",
    "            ax.plot(df_count['episode'],df_count.drop(['episode_start','episode_stop','episode'],axis=1).iloc[:,i],\n",
    "                    color=cm.rainbow(i/self.n_batch))\n",
    "        ax.set_title(\"Count of psychotic episodes\")\n",
    "        ax.set_xlabel(\"Task episode\")\n",
    "        ax.set_ylabel(\"Count of psychotic episodes\")\n",
    "        ax.legend(title=self.title_batch,labels=self.label_batch,\n",
    "                  bbox_to_anchor=(1.05,1),loc='upper left',fontsize=4)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.path_save_analysis,\n",
    "                                 \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())+'_cumul.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def plot_cumulative(self,df_cumul):\n",
    "        fig=plt.figure(figsize=(6,5),dpi=100)\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        for i in range(self.n_batch):\n",
    "            ax.plot(df_cumul['episode'],df_cumul.drop(['episode_start','episode_stop','episode'],axis=1).iloc[:,i],\n",
    "                    color=cm.rainbow(i/self.n_batch))\n",
    "        ax.set_title(\"Cumulative psychosis duration x severity\")\n",
    "        ax.set_xlabel(\"Task episode\")\n",
    "        ax.set_ylabel(\"Duration x Severity\")\n",
    "        ax.legend(title=self.title_batch,labels=self.label_batch,\n",
    "                  bbox_to_anchor=(1.05,1),loc='upper left',fontsize=4)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(self.path_save_analysis,\n",
    "                                 \"{0:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())+'_count.png'))\n",
    "        plt.show()\n",
    "\n",
    "    def pipe_state(self,window=1000,padding=10,learned=True,threshold=[65,67.5]):\n",
    "        df_batchreward=self.batch_load()\n",
    "        df_batchrewardave=self.ave_reward(df_batchreward,window=window,padding=padding)\n",
    "        data_state=self.state_reward(df_batchrewardave,learned=learned,threshold=threshold)\n",
    "        self.heatmap_reward(df_batchrewardave)\n",
    "        self.plot_state(data_state[0])\n",
    "        self.plot_count(data_state[1])\n",
    "        self.plot_cumulative(data_state[2])\n",
    "        return(data_state)\n",
    "        \n",
    "    def pipe_mov(self,window=1000,padding=10):\n",
    "        df_batchreward=self.batch_load()\n",
    "        df_batchrewardave=self.ave_reward(df_batchreward,window=window)\n",
    "        self.plot_reward(df_batchrewardave)\n",
    "\n",
    "    def pipe_block(self,window=100,padding=100):\n",
    "        df_batchreward=self.batch_load()\n",
    "        df_batchrewardave=self.ave_reward(df_batchreward,window=window,padding=padding)\n",
    "        self.plot_reward(df_batchrewardave)\n",
    "\n",
    "    def pipe_hm_mov(self,window=1000,padding=10):\n",
    "        df_batchreward=self.batch_load()\n",
    "        df_batchrewardave=self.ave_reward(df_batchreward,window=window,padding=padding)\n",
    "        self.heatmap_reward(df_batchrewardave)\n",
    "\n",
    "    def pipe_hm_block(self,window=100,padding=100):\n",
    "        df_batchreward=self.batch_load()\n",
    "        df_batchrewardave=self.ave_reward(df_batchreward,window=window,padding=padding)\n",
    "        self.heatmap_reward(df_batchrewardave)\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Average summary data to smooth for vizualization ###################\n",
    "######################################################################\n",
    "'''\n",
    "class MovAveEpisode():\n",
    "    def __init__(self,dataframe,window=100,column=[]):\n",
    "        self.input=dataframe\n",
    "        if len(column)>0:\n",
    "            column_selected=['episode']+column\n",
    "            self.input=self.input[column_selected]\n",
    "        self.window=window\n",
    "        self.length=len(self.input)-self.window+1\n",
    "        #self.length=math.floor(len(self.input)/self.window)\n",
    "        self.calc_movave()\n",
    "\n",
    "    def calc_movave(self):\n",
    "        print('Calculating moving averages over ' + str(self.window) + ' episodes.')\n",
    "        self.output=pd.DataFrame(columns=self.input.columns)\n",
    "        for i in range(self.length):\n",
    "            #print('\\rCalculating ' + str(i) + '/' + str(self.length) + '                 ', end='')\n",
    "            self.output=self.output.append(self.input.iloc[i:(i+self.window),:].mean(),ignore_index=True)\n",
    "            #self.output=self.output.append(self.input.iloc[(self.interval*i):(self.interval*(i+1)),:].mean(),ignore_index=True)\n",
    "        print('Finished calculating moving averages.')\n",
    "'''\n",
    "\n",
    "######################################################################\n",
    "# HDF5 data loading for each type of data ############################\n",
    "######################################################################\n",
    "'''\n",
    "class Load_Activity():\n",
    "    def __init__(self,path_data=None):\n",
    "        if path_data is None:\n",
    "            path=Confirm_Datafolder().path_output\n",
    "        print('Starting hdf5 file loading.')\n",
    "        self.path=path + '/activity'\n",
    "        hdf = pd.HDFStore(self.path+'/activity.h5')\n",
    "        self.output = pd.DataFrame(hdf['activity'])\n",
    "        hdf.close()\n",
    "        print('Finished hdf5 file loading.')\n",
    "\n",
    "class Load_Variable():\n",
    "    def __init__(self,path_data=None):\n",
    "        if path_data is None:\n",
    "            path=Confirm_Datafolder().path_output\n",
    "        print('Starting hdf5 file loading.')\n",
    "        self.path=path + '/model'\n",
    "        hdf = pd.HDFStore(self.path+'/variable.h5')\n",
    "        self.output = pd.DataFrame(hdf['variable'])\n",
    "        hdf.close()\n",
    "        print('Finished hdf5 file loading.')\n",
    "'''\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Data folder configuration ##########################################\n",
    "######################################################################\n",
    "'''\n",
    "class Confirm_Datafolder():\n",
    "    def __init__(self,path_data=path_data,path_data_master=path_data_master):\n",
    "        for i in range(len(path_data_master)):\n",
    "            if os.path.exists(path_data_master[i]):\n",
    "                path_data=path_data_master[i]+'/'+path_data\n",
    "                break\n",
    "            elif i==len(path_data_master)-1:\n",
    "                raise ValueError('Save folder does not exist.')\n",
    "        self.path_output=path_data\n",
    "'''\n",
    "\n",
    "\n",
    "######################################################################\n",
    "# Visualization ######################################################\n",
    "######################################################################\n",
    "'''\n",
    "class RewardAverageGraphBatch():\n",
    "    def __init__(self,paths_data=paths_data):\n",
    "        for p in paths_data:\n",
    "            print('Calculating ' + p + '.')\n",
    "            df=Load_Summary(path_data=p).output\n",
    "            ave=Average_Episode(dataframe=df,extent=100).output\n",
    "            _=Visualize(dataframe=ave,path_data=p)\n",
    "        print('Finished batch calculation.')\n",
    "'''\n",
    "'''\n",
    "class VisAve():   \n",
    "    def __init__(self,df_ave,path_data=path_data,dir_data=dir_data):\n",
    "        self.path=os.path.join(path_data,dir_data)\n",
    "        self.df_ave=df_ave\n",
    "        fig=plt.figure()\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        ax.plot(self.df_ave['episode'],self.df_ave.drop('episode',axis=1))\n",
    "        #ax.plot(np.arange(0,x_test.shape[0],1),y_test)\n",
    "        plt.show()\n",
    "\n",
    "        #fig = self.df_ave.iplot(\n",
    "        #    kind=\"scatter\", asFigure=True,x='episode', title='Reward - Episode',\n",
    "        #    #xTitle='Episode', yTitle='Reward', colors=['blue'])\n",
    "        #    xTitle='Episode', yTitle='Reward')\n",
    "        ##fig = df.iplot(kind=\"scatter\",  asFigure=True,x='Simulation/Global Episode Count', y='Perf/Reward')\n",
    "        #py.offline.plot(fig, filename=self.path + '/Reward.html')\n",
    "'''\n",
    "'''\n",
    "class Vis():\n",
    "    def __init__(self,dataframe,path_data=path_data,key='reward'):\n",
    "        self.df=dataframe\n",
    "        self.path_data=path_data\n",
    "        self.key=key\n",
    "        #cf.set_config_file(offline=True, theme=\"white\", offline_show_link=False)\n",
    "        #cf.go_offline()\n",
    "        #df.plot(x='Simulation/Global Episode Count', y='Performance/Reward')\n",
    "        #plt.show()\n",
    "        #df.iplot(kind=\"scatter\", mode='markers', x='Simulation/Global Episode Count', y='Performance/Reward')\n",
    "\n",
    "        fig = self.df.iplot(\n",
    "            kind=\"scatter\", asFigure=True,x='episode', y=key,\n",
    "            title='Reward - Episode', xTitle='Episode', yTitle='Reward',\n",
    "            colors=['blue'])\n",
    "        #fig = df.iplot(kind=\"scatter\",  asFigure=True,x='Simulation/Global Episode Count', y='Perf/Reward')\n",
    "        py.offline.plot(fig, filename=self.path_data + '/Reward.html')\n",
    "        print('Generated graph.')\n",
    "'''\n",
    "\n",
    "######################################################################\n",
    "# Data Extraction and saving #########################################\n",
    "######################################################################\n",
    "'''\n",
    "class Extract_Checkpoint():\n",
    "    def __init__(self,path_data=path_data):\n",
    "        # Collect summary files\n",
    "        self.path_data=path_data + '/summary'\n",
    "        self.paths_data = glob.glob(os.path.join(self.path_data, '*', 'event*'))\n",
    "\n",
    "        # Extract data from summary files\n",
    "        print('Starting data extraction.')\n",
    "        for p in self.paths_data:\n",
    "            count=0\n",
    "            for e in tf.train.summary_iterator(p):\n",
    "                print('Extracting episode ' + str(int(e.step)), end='/r')\n",
    "                if count==1:\n",
    "                #if count==0:\n",
    "                    colnames=['Simulation/Global Episode Count']+[v.tag for v in e.summary.value]\n",
    "                    self.output=pd.DataFrame(columns=colnames)\n",
    "\n",
    "                if count>0:\n",
    "                #if count>-1:\n",
    "                    data=[e.step]+[v.simple_value for v in e.summary.value]\n",
    "                    self.output.loc[count]=data\n",
    "                count+=1\n",
    "\n",
    "        print('/n')\n",
    "        print('Finished data extraction. ' + str(count) + ' timepoints.')\n",
    "        print('Saving extracted data.')\n",
    "\n",
    "        # Save summary files in hdf5 format\n",
    "        # '/' cannot be used as column names when stored in hdf5, so column names are stored separately\n",
    "        colnames=pd.Series(self.output.columns.values,index=('col'+str(i) for i in range(self.output.shape[1])))\n",
    "        self.output.columns=list('col'+str(i) for i in range(self.output.shape[1]))\n",
    "        hdf=pd.HDFStore(self.path_data+'/summary.h5')\n",
    "        hdf.put('summary',self.output,format='table',append=False,data_columns=True)\n",
    "        hdf.put('colnames',colnames)\n",
    "        hdf.close()\n",
    "        self.output.columns=colnames.tolist()\n",
    "        print('Finished saving data.')\n",
    "'''\n",
    "\n",
    "print('End of file.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loading data.\n100%|██████████| 5/5 [00:00<00:00,  7.35it/s]\nFinished loading data.\nLoading data.\n100%|██████████| 5/5 [00:00<00:00,  7.30it/s]Finished loading data.\n\n"
    }
   ],
   "source": [
    "analysis=BatchAnalysis()\n",
    "df_reward=analysis.batch_load(key='reward')\n",
    "df_arm=analysis.batch_load(key='prob_arm0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window=100\n",
    "padding=10\n",
    "len_out=int((len(df_reward)-window)/padding+1)\n",
    "list_column=df_reward.columns.tolist()\n",
    "list_column.remove('episode')\n",
    "df_ave=pd.DataFrame(columns=['episode_start','episode_stop']+df_reward.columns.tolist())\n",
    "df_slope=pd.DataFrame(columns=['episode_start','episode_stop']+df_reward.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 4991/4991 [00:44<00:00, 112.95it/s]\n"
    }
   ],
   "source": [
    "#for i in tqdm(range(len_out)):\n",
    "for i in tqdm(range(len_out)):\n",
    "    ave_append=[df_reward['episode'].iloc[i*padding],\n",
    "                df_reward['episode'].iloc[i*padding+window-1],\n",
    "                df_reward['episode'].iloc[i*padding:(i*padding+window)].mean()]\n",
    "    slope_append=ave_append\n",
    "    for column in list_column:\n",
    "        reward_window=df_reward[column].iloc[i*padding:(i*padding+window)].tolist()\n",
    "        arm0_window=df_arm[column].iloc[i*padding:(i*padding+window)].tolist()\n",
    "        armdiff_window=[abs(arm0-0.5)*2 for arm0 in arm0_window]\n",
    "        ave=np.mean(reward_window)\n",
    "        slope, intercept, r_value, p_avlue, std_err=stats.linregress(armdiff_window,reward_window)\n",
    "        ave_append=ave_append+[ave]\n",
    "        slope_append=slope_append+[slope]\n",
    "    df_ave=df_ave.append(pd.Series(ave_append,index=['episode_start','episode_stop','episode']+list_column),ignore_index=True)\n",
    "    df_slope=df_slope.append(pd.Series(slope_append,index=['episode_start','episode_stop','episode']+list_column),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Preparing line plot.\n"
    },
    {
     "ename": "AttributeError",
     "evalue": "'BatchAnalysis' object has no attribute 'win_ave'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ef532978dced>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_reward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_ave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-c788257a6b04>\u001b[0m in \u001b[0;36mplot_reward\u001b[1;34m(self, df_reward)\u001b[0m\n\u001b[0;32m    311\u001b[0m             ax.plot(df_reward['episode'],df_reward.drop(['episode_start','episode_stop','episode'],axis=1).iloc[:,i],\n\u001b[0;32m    312\u001b[0m                     color=cm.rainbow(i/self.n_batch))\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Average reward, window: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwin_ave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\", padding: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_ave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Task episode\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Reward\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BatchAnalysis' object has no attribute 'win_ave'"
     ]
    }
   ],
   "source": [
    "analysis.plot_reward(df_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "column=list_column[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_window=df_reward[column].iloc[i*padding:(i*padding+window)].tolist()\n",
    "arm0_window=df_arm[column].iloc[i*padding:(i*padding+window)].tolist()\n",
    "armdiff_window=[abs(arm0-0.5)*2 for arm0 in arm0_window]\n",
    "slope, intercept, r_value, p_avlue, std_err=stats.linregress(armdiff_window,reward_window)\n",
    "ave=np.mean(reward_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_append=[df_reward['episode'].iloc[i*padding],\n",
    "            df_reward['episode'].iloc[i*padding+window-1],\n",
    "            df_reward['episode'].iloc[i*padding:(i*padding+window)].mean()]\n",
    "ave_append=ave_append+[ave]\n",
    "\n",
    "sr_ave=pd.Series(ave_append)"
   ]
  }
 ]
}